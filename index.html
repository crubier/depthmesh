<html>

<head>
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta charset="utf-8">
  <meta property="og:title" content="Depth Mesh Viewer" />
  <meta property="og:description" content="Visualize Google Camera Lens Blur depth maps as a textured meshes." />
  <meta property="og:image" content="http://www.convoluted.net/depthmesh/screenshot.jpg" />
  <title>Depth Mesh Viewer</title>
  <link href='http://fonts.googleapis.com/css?family=Roboto:300,400' rel='stylesheet' type='text/css'>
  <style>
    body {
      background: #000;
    }

    canvas {
      width: 100%;
      height: 100%;
    }

    canvas #toto {
      width: 100%;
      height: auto;
    }

    .overlay {
      width: 250px;
      font-family: Roboto, sans-serif;
      font-weight: 300;
      font-size: 12px;
      background-color: rgba(0, 0, 0, 0.8);
      padding: 10px 20px;
      color: #fff;
      position: absolute;
      z-index: 1;
      right: 0;
    }

    #controls {
      left: 0;
      right: auto;
    }

    #loading-box {
      position: absolute;
      top: 50%;
      left: 50%;
      margin-left: -100px;
      margin-top: -30px;
      width: 200px;
      height: 60px;
      background-color: rgba(0, 0, 0, 0.8);
      box-shadow: 2px 2px 5px rgba(0, 0, 0, 0.4);

    }

    #loading-message {
      font-family: Roboto, sans-serif;
      font-weight: 400;
      font-size: 16px;
      margin-top: 18px;
      text-align: center;
      color: #fff;
    }

    h1 {
      font-weight: 300;
      font-size: 20px;
    }

    h2 {
      font-weight: 400;
      font-size: 12px;
    }

    p {
      margin: 10px 0;
    }

    a {
      text-decoration: inherit;
      font-weight: 400;
      color: inherit;
    }

    a:hover {
      text-decoration: underline;
    }

    #more {
      position: absolute;
      top: 24px;
      right: 20px;
      display: none;
    }

    #less {
      position: absolute;
      top: 24px;
      right: 20px;
      display: inline;
    }

    @media only screen and (max-width: 600px) {
      #description {
        left: 0;
        width: auto;
      }

      #controls {
        visibility: hidden;
      }

      #more {
        display: inline;
      }

      #less {
        display: none;
      }

      #details {
        display: none;
      }
    }
  </style>
</head>

<body>
  <div id="description" class="overlay">
    <h1>Depth Mesh Viewer
      <span id="more"><img src="more.png" width="23" height="23"></span>
      <span id="less"><img src="less.png" width="23" height="23"></span>
    </h1>
    <div id="details">
      <p>Visualizes
        <a href="https://play.google.com/store/apps/details?id=com.google.android.GoogleCamera">
          Google Camera
          <a href="http://googleresearch.blogspot.com/2014/04/lens-blur-in-new-google-camera-app.html">
            Lens Blur</a>
          <a href="https://developers.google.com/depthmap-metadata">depth map data</a> as a textured mesh.</p>
      <p>Built with <a href="http://www.threejs.org/">three.js</a> and
        <a href="https://github.com/spite/android-lens-blur-depth-extractor">android-lens-blur-depth-extractor</a>.
        Inspired by <a href="http://depthy.stamina.pl/">Depthy</a> by Rafał Lindemann and
        <a href="http://www.clicktorelease.com/code/depth-player/">Depth data viewer</a> by
        Jaume Sánchez.
        <p>Source available on <a href="https://github.com/keithito/depthmesh">GitHub</a>.</p>
        <p>Select an image:</p>
        <p>
          <a href="javascript:loadImage('pens')"><img src="thumb_pens.jpg" width="80" height="80"></a>
          <a href="javascript:loadImage('melons')"><img src="thumb_melons.jpg" width="80" height="80"></a>
          <a href="javascript:loadImage('ducks')"><img src="thumb_ducks.jpg" width="80" height="80"></a>
          <a href="javascript:loadImage('cafe')"><img src="thumb_cafe.jpg" width="80" height="80"></a>
          <a href="javascript:loadImage('bridge')"><img src="thumb_bridge.jpg" width="80" height="80"></a>
          <a href="javascript:loadImage('pot')"><img src="thumb_pot.jpg" width="80" height="80"></a>
        </p>
        <p>Or use your own Lens Blur image:</p>
        <input id="uploadFile" type="file" accept="image/*">
    </div>
  </div>
  <div id="controls" class="overlay">
    <h2>Controls:</h2>
    <ul>
      <li>Click and drag to rotate
      <li>Use scroll wheel to zoom
      <li>Right click and drag to move
      <li>Press f to toggle fill
    </ul>
    <canvas id="canvasInput" class="toto" style="height:auto;"></canvas>
    <canvas id="canvasOutput" class="toto" style="height:auto;"></canvas>
    <canvas id="canvasEdge" class="toto" style="height:auto;"></canvas>
  </div>
  <div id="loading-box">
    <div id="loading-message">Loading...</div>
  </div>
  <div id="container"></div>
  <script src="lib/three.min.js"></script>
  <script src="lib/three-controls.js"></script>
  <script src="lib/depth-extractor.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
  <script async src="lib/opencv.js" onload="onOpenCvReady();"></script>
  <script>
    /* Copyright (c) 2014 Keith Ito. MIT License: http://convoluted.net/depthmesh/LICENSE */

    function onOpenCvReady() {
      var VERTEX_SHADER = [
        'varying vec2 vUv;',
        'void main() {',
        '  vUv = uv;',
        '  gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);',
        '}',
      ].join('\n');

      var FRAGMENT_SHADER = [
        'uniform sampler2D tex;',
        'varying vec2 vUv;',
        'void main() {',
        '  gl_FragColor = texture2D(tex, vUv);',
        '}',
      ].join('\n');

      var MAX_EDGE_PX = 1024;
      var IMAGE_PLANE_SIZE = 12;

      function buildChunk(size, depthData, focalDistance, imagePlaneWidth, near, far,
        startRow, limitRow, positions, texCoords, indices) {
        var width = size.width;
        var height = size.height;

        // Generate position and color.
        var step = imagePlaneWidth / width;
        var stepTexX = 1.0 / width;
        var stepTexY = 1.0 / height;
        var y = 0.5 * imagePlaneWidth * (height / width) - startRow * step;
        var texY = 1 - startRow * stepTexY;
        var depthIndex = startRow * width * 4;
        var i, j;
        for (j = startRow; j < limitRow; j++) {
          var x = -0.5 * imagePlaneWidth;
          var texX = 0;
          for (i = 0; i < width; i++) {
            var dn = depthData[depthIndex] * (1 / 255);
            var depth = (far * near) / (far - dn * (far - near));
            var spread = depth / focalDistance;
            positions.push(x * spread, y * spread, -depth);
            texCoords.push(texX, texY);
            x += step;
            texX += stepTexX;
            depthIndex += 4;
          }
          y -= step;
          texY -= stepTexY;
        }

        // Generate indices.
        var baseIndex = 0;
        for (var j = startRow; j < limitRow - 1; j++) {
          for (var i = 0; i < width - 1; i++) {
            indices.push(
              baseIndex, baseIndex + width, baseIndex + 1,
              baseIndex + 1, baseIndex + width, baseIndex + width + 1);
            baseIndex++;
          }
          baseIndex++;
        }
      }

      function buildGrid(size, depthData, focalDistance, imagePlaneWidth, near, far) {
        var positions = [];
        var texCoords = [];
        var indices = [];
        var offsets = [];

        // WebGL only allows 16-bit indices, so we may need to generate multiple chunks of geometry.
        var rowsPerChunk = Math.min(size.height, Math.floor(65536 / size.width) - 1);
        for (var row = 0; row < size.height; row += rowsPerChunk) {
          var limitRow = Math.min(size.height, row + rowsPerChunk + 1);
          var start = indices.length;
          var index = positions.length / 3;
          buildChunk(size, depthData, focalDistance, imagePlaneWidth, near, far,
            row, limitRow, positions, texCoords, indices);
          offsets.push({
            start: start,
            index: index,
            count: (indices.length - start)
          });
        }

        var geometry = new THREE.BufferGeometry();
        geometry.addAttribute('position', Float32Array, positions.length / 3, 3);
        geometry.attributes.position.array = new Float32Array(positions);
        geometry.addAttribute('uv', Float32Array, texCoords.length / 2, 2);
        geometry.attributes.uv.array = new Float32Array(texCoords);
        geometry.addAttribute('index', Uint16Array, indices.length, 1);
        geometry.attributes.index.array = new Uint16Array(indices);
        geometry.offsets = offsets;
        return geometry;
      }

      function getDepthData(img, size) {
        var canvas = document.createElement('canvas');
        canvas.width = size.width;
        canvas.height = size.height;
        var ctx = canvas.getContext('2d');
        ctx.drawImage(img, 0, 0, size.width, size.height);
        var depthData = ctx.getImageData(0, 0, size.width, size.height);
        return depthData.data;
      }

      function getDepthEdgeData(img, size) {


        // var canvas = document.createElement('canvas');
        // canvas.setAttribute("id", "canvasEdge");
        var canvasEdge = document.getElementById('canvasEdge');
        canvasEdge.width = size.width;
        canvasEdge.height = size.height;
        canvasEdge.setAttribute("style", "max-width: 100%;max-height:300px;width:auto;height: auto;")
        var ctxEdge = canvasEdge.getContext('2d');
        ctxEdge.drawImage(img, 0, 0, size.width, size.height);

        let src = cv.imread('canvasEdge');
        let dst = new cv.Mat();
        cv.cvtColor(src, src, cv.COLOR_RGB2GRAY, 0);
        // You can try more different parameters
        // cv.Canny(src, dst, 600, 700, 7, false);
        cv.Canny(src, dst, 6000, 7000, 7, false);



        var canvasOutput = document.getElementById('canvasOutput');
        canvasOutput.width = size.width;
        canvasOutput.height = size.height;
        canvasOutput.setAttribute("style", "max-width: 100%;max-height:300px;width:auto;height: auto;")
        cv.imshow('canvasOutput', dst);
        src.delete();
        dst.delete();
      }

      function getGridSize(image) {
        var maxEdge = Math.max(image.width, image.height);
        if (maxEdge > MAX_EDGE_PX) {
          var aspectRatio = image.width / image.height;
          if (aspectRatio >= 1) {
            return {
              width: MAX_EDGE_PX,
              height: Math.round(MAX_EDGE_PX / aspectRatio)
            };
          } else {
            return {
              width: Math.round(MAX_EDGE_PX * aspectRatio),
              height: MAX_EDGE_PX
            };
          }
        } else {
          return {
            width: image.width,
            height: image.height
          };
        }
      }


      var scene, camera, controls;
      var mesh, lines;
      var isShowingLines;

      function createScene(color, depth, focalDistance) {
        var aspectRatio = window.innerWidth / window.innerHeight;
        scene = new THREE.Scene();
        camera = new THREE.PerspectiveCamera(40, aspectRatio, 0.1, 400);

        var colorMime = color.mime || 'image/jpeg';
        var tex = THREE.ImageUtils.loadTexture('data:' + colorMime + ';base64,' + color.data,
          undefined,
          function () {
            var gridSize = getGridSize(tex.image);
            var uniforms = {
              tex: {
                type: 't',
                value: tex
              }
            };

            var canvasInput = document.getElementById('canvasInput');
            canvasInput.width = gridSize.width;
            canvasInput.height = gridSize.height;
            canvasInput.setAttribute("style", "max-width: 100%;max-height:300px;width:auto;height: auto;")
            var ctxEdge = canvasInput.getContext('2d');
            ctxEdge.drawImage(tex.image, 0, 0, gridSize.width, gridSize.height);

            var material = new THREE.ShaderMaterial({
              uniforms: uniforms,
              vertexShader: VERTEX_SHADER,
              fragmentShader: FRAGMENT_SHADER,
              side: THREE.DoubleSide,
            });

            var imagePlaneWidth = IMAGE_PLANE_SIZE;
            if (gridSize.width < gridSize.height) {
              imagePlaneWidth = IMAGE_PLANE_SIZE * gridSize.width / gridSize.height;
            }

            var depthMime = depth.mime || 'image/png';
            var img = new Image();
            img.onload = function () {
              hideMessage();
              getDepthEdgeData(img, gridSize);
              var geometry = buildGrid(gridSize, getDepthData(img, gridSize), focalDistance,
                imagePlaneWidth, parseFloat(depth.near), parseFloat(depth.far));
              mesh = new THREE.Mesh(geometry, material);
              lines = new THREE.Line(geometry, material);
              mesh.translateZ(focalDistance);
              lines.translateZ(focalDistance);
              scene.add(mesh);
              isShowingLines = false;

              camera.position.set(0, 0, focalDistance);
              camera.lookAt(new THREE.Vector3(0, 0, 0));
              camera.up.set(0, 1, 0);

              controls = new THREE.TrackballControls(camera, renderer.domElement);
              controls.rotateSpeed = 0.1;



            };

            img.src = 'data:' + depthMime + ';base64,' + depth.data;
          });
      }

      function toggleMesh() {
        if (mesh && lines) {
          if (isShowingLines) {
            scene.remove(lines);
            scene.add(mesh);
            isShowingLines = false;
          } else {
            scene.remove(mesh);
            scene.add(lines);
            isShowingLines = true;
          }
        }
      }

      function showMessage(msg) {
        $('#loading-box').show();
        $('#loading-message').text(msg || 'Loading...');
      }

      function hideMessage() {
        $('#loading-box').hide();
      }

      function loadImage(name) {
        showMessage();
        var d = new DepthReader();
        d.loadFile(name + '.jpg', function () {

          createScene(d.image, d.depth, parseFloat(d.focus.focalDistance));
        }, function (error) {
          console.log(error);
          showMessage(error);
        });
      }

      function uploadFile(file) {
        if (file && file.type.match(/image.*/)) {
          showMessage();
          var reader = new FileReader();
          reader.onload = function (e) {
            var d = new DepthReader();
            d.parseFile(reader.result, function () {
              createScene(d.image, d.depth, parseFloat(d.focus.focalDistance));
            }, function (error) {
              console.log(error);
              showMessage(error);
            });
          }
          reader.readAsArrayBuffer(file);
        }
      }

      if (!window.WebGLRenderingContext) {
        showMessage('Sorry, your browser does not support WebGL.');
        return;
      }
      var renderer = new THREE.WebGLRenderer();
      renderer.setSize(window.innerWidth, window.innerHeight);
      $('#container').append(renderer.domElement);

      $('#uploadFile').on('change', function () {
        uploadFile($('#uploadFile').get(0).files[0]);
      });

      $('#more').click(function () {
        $('#details').show('fast');
        $('#more').hide('fast');
        $('#less').show('fast');
      });

      $('#less').click(function () {
        $('#details').hide('fast');
        $('#more').show('fast');
        $('#less').hide('fast');
      });

      $(document).keypress(function (e) {
        if (e.which == 102) {
          toggleMesh();
        }
      });

      var render = function () {
        requestAnimationFrame(render);
        if (controls && scene && camera) {
          controls.update();
          renderer.render(scene, camera);
        }
      };
      render();
      loadImage('pens');

      this.loadImage = loadImage;
    };
  </script>

</body>

</html>

<!-- <!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Hello OpenCV.js</title>
</head>
<body>
<h2>Hello OpenCV.js</h2>
<p id="status">OpenCV.js is loading...</p>
<div>
  <div class="inputoutput">
    <img id="imageSrc" alt="No Image" />
    <div class="caption">imageSrc <input type="file" id="fileInput" name="file" /></div>
  </div>
  <div class="inputoutput">
    <canvas id="canvasOutput" ></canvas>
    <div class="caption">canvasOutput</div>
  </div>
</div>
<script type="text/javascript">
let imgElement = document.getElementById('imageSrc');
let inputElement = document.getElementById('fileInput');
inputElement.addEventListener('change', (e) => {
  imgElement.src = URL.createObjectURL(e.target.files[0]);
}, false);
imgElement.onload = function() {
  let mat = cv.imread(imgElement);
  cv.imshow('canvasOutput', mat);
  mat.delete();
};
function onOpenCvReady() {
  document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
}
</script>

</body>
</html> -->